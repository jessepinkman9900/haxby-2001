{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2\n",
    "\n",
    "Srinivas Kota  \n",
    "2018101043  \n",
    "Replicating results of Haxby 2001  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DOWNLOAD DATA\n",
    "from nilearn import datasets\n",
    "\n",
    "DATA_DIR = './data/'\n",
    "haxby_dataset = datasets.fetch_haxby(data_dir=DATA_DIR, fetch_stimuli=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1. What is the repetition time (TR) in seconds?\n",
    "\n",
    "#### Ans.\n",
    "Repetition Time (TR) = 2.5 seconds = 2500 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_r = 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. How many brain volumes are acquired in time?\n",
    "\n",
    "### Ans\n",
    "There are 1452 brain volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image\n",
    "\n",
    "anatomical = image.load_img(img=haxby_dataset['anat'])\n",
    "functional = image.load_img(img=haxby_dataset['func'])\n",
    "\n",
    "voxels = functional.get_fdata()\n",
    "print(f\"Shape of voxels: {voxels.shape}\")\n",
    "print(f\"Volumes: {voxels.shape[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ind = 10\n",
    "voxel_vs_t = voxels[ind][ind][ind]\n",
    "\n",
    "plt.plot(range(len(voxel_vs_t)) * t_r, voxel_vs_t)\n",
    "plt.xlabel(\"Time (t)\")\n",
    "plt.ylabel(\"Voxel Intensity (I)\")\n",
    "plt.title(f\"Voxel Intensity vs Time for voxel at ({ind}, {ind}, {ind})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3. What is the voxel resolution/dimension of the functional image? Is it isotropic or anisotropic?\n",
    "\n",
    "#### Ans\n",
    "The functional image is anisotropic. The dimension of the functional image is [3.5, 3.75, 3.75]. This is a cuboid, all sides of voxel are not the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(functional.header)\n",
    "print(f\"Pixel dimension: {functional.header['pixdim']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4. List out the categories that are used in the experiments for visual object recognition task? Plot one image from any of the two categories.\n",
    "\n",
    "#### Ans\n",
    "Labels:\n",
    " {'chair', 'bottle', 'scrambledpix', 'house', 'cat', 'shoe', 'scissors', 'face', 'rest'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "session = pd.read_csv(haxby_dataset['session_target'][0], ' ')\n",
    "\n",
    "print(f\"Shape of dataframe: {session.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Categories in experiment for object recognition task:\\n {set(session['labels'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_image = haxby_dataset['stimuli']['cats'][0]\n",
    "scissor_image = haxby_dataset['stimuli']['scissors'][0]\n",
    "\n",
    "import matplotlib.image as pimg\n",
    "\n",
    "def plot_image(path):\n",
    "    plt.imshow(pimg.imread(path))\n",
    "    plt.title(path)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_image(cat_image)\n",
    "plot_image(scissor_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5. For how many runs/sessions are the experiments repeated?\n",
    "\n",
    "#### Ans\n",
    "We have 12 unique runs of the experment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sessions in experiemnt: {len(set(session['chunks']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masking, Plotting, analyse BOLD signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiMasker\n",
    "def get_mask(nii):\n",
    "    img = image.load_img(nii)\n",
    "    mask = NiftiMasker(mask_img=img)\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_vt = get_mask(haxby_dataset['mask_vt'])\n",
    "mask_house = get_mask(haxby_dataset['mask_house'])\n",
    "mask_face = get_mask(haxby_dataset['mask_face'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functional_vt = mask_vt.fit_transform(functional)\n",
    "functional_house = mask_house.fit_transform(functional)\n",
    "functional_face = mask_face.fit_transform(functional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_bold_v_time(vt, face, house, time, title):\n",
    "    plt.plot(np.mean(vt[:time], axis=1), label='Mask VT')\n",
    "    plt.plot(np.mean(house[:time], axis=1), label='Mask HOUSE')\n",
    "    plt.plot(np.mean(face[:time], axis=1), label='Mask FACE')\n",
    "    plt.xlabel('Time (t)')\n",
    "    plt.ylabel('BOLD Signal')\n",
    "    plt.title(title)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "time = 75\n",
    "plot_bold_v_time(functional_vt, functional_face, functional_house, time, title=\"Mean BOLD Signal v Time\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BOLD signal is noisy and has lot of variance. We smooth this signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highpass_filter = 0.008\n",
    "standardize = True\n",
    "detrend = True\n",
    "smoothing_fwhm = 6\n",
    "\n",
    "def get_smooth_mask(nii, t_r=2.5, high_pass=0.008, standardize=True, detrend=True, smoothing_fwhm=6):\n",
    "    mask_img = image.load_img(img=nii)\n",
    "    mask = NiftiMasker(mask_img=mask_img, t_r=t_r, high_pass=high_pass, standardize=standardize, detrend=detrend, smoothing_fwhm=smoothing_fwhm)\n",
    "    return mask\n",
    "\n",
    "smooth_mask_vt = get_smooth_mask(haxby_dataset['mask_vt'])\n",
    "smooth_mask_face = get_smooth_mask(haxby_dataset['mask_face'])\n",
    "smooth_mask_house = get_smooth_mask(haxby_dataset['mask_house'])\n",
    "\n",
    "smooth_functional_vt = smooth_mask_vt.fit_transform(functional)\n",
    "smooth_functional_face = smooth_mask_face.fit_transform(functional)\n",
    "smooth_functional_house = smooth_mask_house.fit_transform(functional)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 75\n",
    "plot_bold_v_time(smooth_functional_vt, smooth_functional_face, smooth_functional_house, time, title=\"Smooth BOLD Signal vs Time\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. After plotting the average signals from each of those masks (each 1D):\n",
    "6.1 Does the signals appear like a block design or event related design?  \n",
    "6.2 From the raw timeseries signals, can you see which stimulus evoked a larger response? Is it vt or face or house?\n",
    "\n",
    "### Ans\n",
    "6.1 The experiment has Block Design. We can see periodic activation and rest in the BLOCK signal vs time graph.  \n",
    "\n",
    "6.2 Responses to the FACE seem to large in magnitude than response for HOUSE or VT in the observed time frame. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7. What are the importance of high pass, standardize, detrend such parameters in fMRI time series analysis? Can you state their role? What could be influencing the results if such parameters are not specified?\n",
    "\n",
    "#### Ans\n",
    "##### High-Pass  \n",
    "High Pass filter only lets higher frequencies pass through and blocks lower frequencies. The fMRI data obtained usually contains a lot of noise from the subjust such as breathing and from the machine such as vibraionts. This leads to the subject being unable to stay still across the scan leading to noisy data. We know that the hemodynamic response has frequency $>0.1 Hz$, therefore we can block all frequencies below this range using a HighPass filter  \n",
    "  \n",
    "##### Standardise  \n",
    "Standardisation brings the amplitude of the of fMRI data to a single comparable range. While obtaining fMRI data, each voxel can give a different range of magnitudes. By applying standardisation we bring the magnitude of all voxels into a comparable range.  \n",
    "  \n",
    "##### Detrend  \n",
    "Detrend converts the timeseries into a stationary timeseries by removing the linear trend in BOLD timesperies. This linear trend is observed as an increasing trend that can be caused by scanner instablility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GLM with Nilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = session['labels']\n",
    "sessions = session['chunks']\n",
    "\n",
    "session_number = 0\n",
    "\n",
    "session_conditions = conditions[sessions == session_number]\n",
    "\n",
    "n_scans = len(session_conditions)\n",
    "frame_times = t_r * np.arange(n_scans)\n",
    "\n",
    "duration = t_r * np.ones(n_scans)\n",
    "\n",
    "events = pd.DataFrame(\n",
    "    {\n",
    "        'onset': frame_times,\n",
    "        'trial_type': session_conditions,\n",
    "        'duration': duration\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8. Observe the difference in the data array shape of conditions and conditions session? What does that mean? You can print the shapes of both arrays and tell us why they are different?\n",
    "\n",
    "### Ans\n",
    "Conditions has 1452 elements.  \n",
    "Session Conditions has 121 elements.  \n",
    "Conditions is universal set of conditions for all sessions. Session Conditions is a subset of this universal set we obtain by filtering for a given session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of conditions: {conditions.shape}\")\n",
    "print(f\"Shape of sessions conditions: {session_conditions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "\n",
    "highpass_filter = 0.008\n",
    "smoothing_fwhm = 4\n",
    "glm = FirstLevelModel(\n",
    "    t_r=t_r,\n",
    "    mask_img=haxby_dataset.mask,\n",
    "    high_pass=highpass_filter,\n",
    "    smoothing_fwhm=smoothing_fwhm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q9. Why is smoothing necessary? What type of smoothing is implemented in the code?\n",
    "\n",
    "#### Ans.\n",
    "As we have discussed, fMRI data tends to have lot of noise due to human and environmental conditions during scan. By applying smoothing we aim to reduce the amount of noice and increase the signal to noise ratio. This is case due to the assumption that the noise in the sinal covers a smaller spatial region and therfore will even out faster than the main signal.  \n",
    "  \n",
    "Nilearn uses Gaussian Smoothing. The strenght of smoothing is defined by the `fwhm` value, i.e full width at half maximum and applying this value in each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_maps = []\n",
    "conditions_label = []\n",
    "session_label = []\n",
    "\n",
    "from nilearn.image import index_img\n",
    "\n",
    "session_number = 1\n",
    "\n",
    "fmri_session = index_img(functional, sessions == session_number)\n",
    "\n",
    "glm.fit(fmri_session, events=events)\n",
    "\n",
    "conditions = ['face', 'scrambledpix', 'scissors', 'shoe', 'bottle', 'cat', 'chair', 'house']\n",
    "\n",
    "for condition_ in conditions:\n",
    "    z_maps.append(glm.compute_contrast(condition_))\n",
    "    conditions_label.append(condition_)\n",
    "    session_label.append(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q10. In the code, what is the role of nilearn.image.index img? Why is it important to apply on functional image?\n",
    "\n",
    "#### Ans\n",
    "`nilearn.image.index_img` extracts the frames in a given series of indexes. By applying it on the functional image and giving it a set of indexes we are picking only those images that are relavant to the session. Functional image has 1452 images, but session 1 has only 121 images. By using `index_img` we pick the images out of functional image that are relevant to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q11. Dig into the FirstLevelModel and helps us understand what type of regression technique is used to estimate Î² maps? Which software is Nilearn dependent on for that regression technique?\n",
    "\n",
    "#### Ans\n",
    "FirstLevelModel is a multiple linear regression model. It used auto-regression to estimate the $\\beta$ maps. It fits the BOLD timeseries data $Y$ to the regressors in the design matrix $X$. Nilearn used `numpy` to implement the regression technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q12. Plot the design matrices attribute using nilearn.plotting.plot design matrix. What does each column represents? Does this makes sense with GLM design that is shown on Figure 2? Briefly elaborate how it made sense to you?\n",
    "\n",
    "#### Ans.\n",
    "Each column represents a regression. The regression variables we have are the experiment conditions, the motion variables and a constant.\n",
    "This observation makes sense with the GLM design shown. The BOLD data $Y$ is fit using multiple regression on $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "def plot_glm_design_matrix(dm):\n",
    "    plotting.plot_design_matrix(dm)\n",
    "    plotting.show()\n",
    "\n",
    "plot_glm_design_matrix(glm.design_matrices_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q13. What is now the scanning length of fMRI per session?\n",
    "\n",
    "#### Ans.\n",
    "We have 121 frames for each session. Duration of each scan is `t_r = 2.5 seconds`.  \n",
    "Total duration of scan = $302.5$ seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Duration of scan: {t_r * fmri_session.shape[-1]} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q14. What is compute contrast? What it does? Plot the compute constrast outputs for all conditions using nilearn.plotting.plot stat map with bg img as Haxby data anatomical image. What is this output type z maps means?\n",
    "\n",
    "#### Ans\n",
    "##### Compute Contrast\n",
    "Contrast map is the difference between the beta map (condition is active) and the rest map. Compute contrast calculates the constrast maps given a condition.\n",
    "\n",
    "Contrast maps give us the regions that are active when the condition is active.\n",
    "\n",
    "##### Z-maps\n",
    "`z_maps` are constrast maps with the values standarised with variance 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contrast_map(conditions, z_maps, bg_img):\n",
    "    for i, condition_ in enumerate(conditions):\n",
    "        plotting.plot_stat_map(stat_map_img=z_maps[i], bg_img=bg_img, title=f\"Condition: {condition_}\")\n",
    "    plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contrast_map(conditions=conditions_label, z_maps=z_maps, bg_img=haxby_dataset['anat'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GLM for all Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "mask_img = haxby_dataset['mask']\n",
    "high_pass = 0.008\n",
    "smoothing_fwhm = 4\n",
    "\n",
    "z_maps = []\n",
    "conditions_label = []\n",
    "each_session_label = []\n",
    "\n",
    "sessions = session['chunks']\n",
    "conditions = session['labels']\n",
    "\n",
    "for session_number in tqdm(set(sessions)):\n",
    "    session_conditions = conditions[sessions == session_number]\n",
    "\n",
    "    n_scans = len(session_conditions)\n",
    "\n",
    "    frame_times = t_r * np.arange(n_scans)\n",
    "    duration = t_r * np.ones(n_scans)\n",
    "\n",
    "    events = pd.DataFrame({\n",
    "        'onset': frame_times,\n",
    "        'trial_type': session_conditions,\n",
    "        'duration': duration\n",
    "    })\n",
    "\n",
    "    glm = FirstLevelModel(\n",
    "        t_r=t_r,\n",
    "        mask_img=mask_img,\n",
    "        high_pass=high_pass,\n",
    "        smoothing_fwhm=smoothing_fwhm\n",
    "    )\n",
    "\n",
    "    fmri_session = index_img(functional, sessions == session_number)\n",
    "\n",
    "    glm.fit(fmri_session, events=events)\n",
    "\n",
    "    for condition_ in conditions:\n",
    "        z_maps.append(glm.compute_contrast(condition_))\n",
    "        conditions_label.append(condition_)\n",
    "        each_session_label.append(session_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q15. Tell us what this example tried to replicate in the paper. Does the classification accuracies per ROI across different categories makes sense with the outcomes of the paper? Convince us by writing a brief paragraph to assess your understanding.\n",
    "\n",
    "#### Ans\n",
    "We try to replicate the HAXBY experiment by measuring accuracies using the VT, HOUSE and FACE masks. We observe that the accuracy for each mask are similar to those observed in the paper. We find that the Ventral Temporal (VT) mask outperforms the HOUSE and FACE mask. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.decoding import Decoder\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "decoder = Decoder(\n",
    "    estimator='svc',\n",
    "    cv=LeaveOneGroupOut,\n",
    "    mask=mask_img,\n",
    "    standardize=False,\n",
    "    screening_percentile=3,\n",
    ")\n",
    "\n",
    "decoder.fit(z_maps, conditions_label, groups=each_session_label)\n",
    "\n",
    "accuracy = np.mean(list(decoder.cv_scores_.values()))\n",
    "print(f\"Classification Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db67ee063644a13223cf8004de49cc36e9d15b63871a61fbd3f89c5017f6f4e5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
